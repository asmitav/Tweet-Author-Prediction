{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#cleaning text data using textacy\n",
    "from textacy.preprocess import preprocess_text\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('data/training_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text = tweets['text'].values\n",
    "clean_text = [preprocess_text(x, fix_unicode=True, lowercase=True, no_urls=True, no_emails=True, no_phone_numbers=True, no_currency_symbols=True,\n",
    "                              no_punct=True, no_accents=True)\n",
    "              for x in tweet_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "    Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['prattprattpratt', 'azizansari', 'VancityReynolds', 'evilhag',\n",
       "       'Nick_Offerman', 'mradamscott', 'JimOHeir', 'MeganMullally'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.screen_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.125\n"
     ]
    }
   ],
   "source": [
    "# creating target\n",
    "def target_encod(x):\n",
    "    if x == 'prattprattpratt': return 1\n",
    "    elif x == 'azizansari': return 2\n",
    "    elif x == 'VancityReynolds': return 3\n",
    "    elif x == 'evilhag': return 4\n",
    "    elif x == 'Nick_Offerman': return 5\n",
    "    elif x == 'mradamscott': return 6\n",
    "    elif x == 'JimOHeir': return 7\n",
    "    else: return 8\n",
    "\n",
    "y = tweets['screen_name'].map(lambda x: x).values\n",
    "print (max(pd.Series(y).value_counts(normalize=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 2000)\n"
     ]
    }
   ],
   "source": [
    "# Vectorizing with TF-IDF Vectorizer and creating X matrix\n",
    "tfv = TfidfVectorizer(ngram_range=(2,4), max_features=2000)\n",
    "X = tfv.fit_transform(clean_text).todense()\n",
    "print (X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2000 out of 2000 | elapsed:  8.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': array([1.00000e-05, 1.12332e-05, ..., 8.90215e-01, 1.00000e+00])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lr = LogisticRegression()\n",
    "params = {'penalty': ['l1', 'l2'], 'C':np.logspace(-5,0,100)}\n",
    "#Grid searching to find optimal parameters for Logistic Regression\n",
    "gs = GridSearchCV(lr, param_grid=params, cv=10, verbose=1)\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.7054802310718645, 'penalty': 'l2'}\n",
      "0.402375\n"
     ]
    }
   ],
   "source": [
    "print (gs.best_params_)\n",
    "print (gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.37875, 0.35375, 0.43   , 0.4325 , 0.44125, 0.42125, 0.37625,\n",
       "       0.4    , 0.43375, 0.35625])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(LogisticRegression(C=0.7054802310718645, penalty='l2'), X, y, cv=10)\n",
    "\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.7054802310718645, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = LogisticRegression(C=0.7054802310718645, penalty='l2')\n",
    "estimator.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prattprattpratt</th>\n",
       "      <th>azizansari</th>\n",
       "      <th>VancityReynolds</th>\n",
       "      <th>evilhag</th>\n",
       "      <th>Nick_Offerman</th>\n",
       "      <th>mradamscott</th>\n",
       "      <th>JimOHeir</th>\n",
       "      <th>MeganMullally</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.080199</td>\n",
       "      <td>0.101831</td>\n",
       "      <td>0.295989</td>\n",
       "      <td>0.118075</td>\n",
       "      <td>0.085917</td>\n",
       "      <td>0.120500</td>\n",
       "      <td>0.122639</td>\n",
       "      <td>0.074851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.079723</td>\n",
       "      <td>0.117248</td>\n",
       "      <td>0.196920</td>\n",
       "      <td>0.106517</td>\n",
       "      <td>0.119884</td>\n",
       "      <td>0.123106</td>\n",
       "      <td>0.133167</td>\n",
       "      <td>0.123435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prattprattpratt  azizansari  VancityReynolds   evilhag  Nick_Offerman  \\\n",
       "0         0.080199    0.101831         0.295989  0.118075       0.085917   \n",
       "1         0.079723    0.117248         0.196920  0.106517       0.119884   \n",
       "\n",
       "   mradamscott  JimOHeir  MeganMullally  \n",
       "0     0.120500  0.122639       0.074851  \n",
       "1     0.123106  0.133167       0.123435  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prep our source as TfIdf vectors\n",
    "source_test = [\n",
    "    \"Good Morning America. @GMA (is the name of a television program I will appear on this morning) @heartsbeatloud\",\n",
    "    \"omg every interview should be like this üëèüèΩüôåüèΩüëçüèΩ\"\n",
    "   ]\n",
    "\n",
    "Xtest = tfv.transform(source_test)\n",
    "pd.DataFrame(estimator.predict_proba(Xtest), columns=['prattprattpratt', 'azizansari', 'VancityReynolds', 'evilhag',\n",
    "       'Nick_Offerman', 'mradamscott', 'JimOHeir', 'MeganMullally'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
